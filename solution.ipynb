{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, date\n",
    "from sqlalchemy import DATE, TEXT, DATETIME, INTEGER\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "def date_parser(data_str):\n",
    "    \"\"\"\n",
    "        Format any date in YYYY-MM-DD HH:MM:SS\n",
    "    Args:\n",
    "        data_str (str): string with the date\n",
    "\n",
    "    Returns:\n",
    "        str: string with the date formatted in YYYY-MM-DD HH:MM:SS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tenta analisar a data de entrada em diferentes formatos\n",
    "        data_str = str(data_str)\n",
    "        if data_str[:2] == '00':\n",
    "            data_str = '20'+str(data_str)[2:]\n",
    "        # data = datetime(year=int('20'+data_str[2:4]), month=int(data_str[5:7], 10), day=int(data_str[8:10]), hour=int(data_str[11:13]), minute=int(data_str[14:16]), second=int(data_str[17:19]),microsecond=int(0))\n",
    "        data = datetime.strptime(data_str, '%Y-%m-%d %H:%M:%S')\n",
    "        if data_str[:2] == '00':\n",
    "            print(data_str)\n",
    "            print(data)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            data = datetime.strptime(data_str, '%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                data = datetime.strptime(data_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    data = datetime.strptime(data_str, '%d/%m/%Y %H:%M:%S')\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        data = datetime.strptime(data_str, '%d/%m/%Y %H:%M')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            data = datetime.strptime(data_str, '%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                data = datetime.strptime(data_str, '%Y-%m-%d %H:%M')\n",
    "                            except ValueError:\n",
    "                                return None  # Retornar None se a data não pôde ser analisada\n",
    "\n",
    "    # Formate a data no formato desejado\n",
    "    data_formatada = data.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    data_obj = datetime.strptime(data_formatada, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return data_obj\n",
    "\n",
    "def trf_dtypes(schema,dataframe):\n",
    "    \"\"\"\n",
    "    Transforma os tipos de dados do dataframe de acordo com o schema especificado.\n",
    "\n",
    "    Args:\n",
    "        schema_bq (dict): Dicionário contendo o schema do BigQuery, com os nomes das colunas e os tipos de dados.\n",
    "        dataframe (pandas.DataFrame): O dataframe a ser transformado.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário contendo as informações do schema e o dataframe transformado.\n",
    "    \"\"\"\n",
    "    # print(dataframe.dtypes)\n",
    "    de_para = {\n",
    "            DATETIME: 'DATETIME',\n",
    "            DATE: 'DATE',\n",
    "            TEXT: 'TEXT',\n",
    "            INTEGER: 'INTEGER'\n",
    "        }\n",
    "    for key, value in schema.items():\n",
    "        # print(f'Parsing {key} for type {value}')\n",
    "        type = de_para.get(value)\n",
    "        # print(f'Parsing {key} for type {type}')\n",
    "        match(type):\n",
    "            case 'INTEGER':\n",
    "                dataframe[key] = dataframe[key].astype(pd.Int64Dtype())\n",
    "            case 'DATETIME':\n",
    "                dataframe[key] = dataframe[key].apply(date_parser)\n",
    "                # dataframe[key] = dataframe[key].apply(lambda x: x if not pd.isna(x) else None)\n",
    "                # dataframe[key] = pd.to_datetime(dataframe[key],format='%Y-%m-%d %H:%M:%S')\n",
    "            case 'DATE':\n",
    "                # dataframe[key] = dataframe[key].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').date())\n",
    "                # dataframe[key] = dataframe[key].apply(lambda x: None if pd.isna(x) else x)\n",
    "                dataframe[key] = pd.to_datetime(dataframe[key], format='%Y-%m-%d')\n",
    "            # case 'Float':\n",
    "            #     dataframe[key] = dataframe[key].apply(trf_numeric)\n",
    "            #     dataframe[key] = dataframe[key].round(decimals=7).astype(float)\n",
    "            #     context = decimal.Context(prec=10,Emax=99999, Emin=-99999)\n",
    "            #     dataframe[key] = dataframe[key].apply(context.create_decimal_from_float)\n",
    "            case 'TEXT':\n",
    "                # dataframe[key] = dataframe[key].apply(trf_str)\n",
    "                dataframe[key] = dataframe[key].replace(\"null\", None)\n",
    "                dataframe[key] = dataframe[key].astype(pd.StringDtype())\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solution for the first question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_30128\\2379615460.py:60: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_json.to_sql('vra', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace',dtype=schema)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----[E] Extracting data of JSON files-----\n",
      "\n",
      "Extracted VRA_20211.json -> 58550 rows\n",
      "Extracted VRA_202110.json -> 59430 rows\n",
      "Extracted VRA_202111.json -> 64004 rows\n",
      "Extracted VRA_20212.json -> 43692 rows\n",
      "Extracted VRA_20213.json -> 39514 rows\n",
      "Extracted VRA_20214.json -> 29122 rows\n",
      "Extracted VRA_20215.json -> 35750 rows\n",
      "Extracted VRA_20216.json -> 40955 rows\n",
      "Extracted VRA_20217.json -> 53313 rows\n",
      "Extracted VRA_20218.json -> 54928 rows\n",
      "Extracted VRA_20219.json -> 56545 rows\n",
      "\n",
      "Extracted -> 535803 rows\n",
      "\n",
      "icao_empresa_aerea        object\n",
      "numero_voo                object\n",
      "codigo_autorizacao        object\n",
      "codigo_tipo_linha         object\n",
      "icao_aerodromo_origem     object\n",
      "icao_aerodromo_destino    object\n",
      "partida_prevista          object\n",
      "partida_real              object\n",
      "chegada_prevista          object\n",
      "chegada_real              object\n",
      "situacao_voo              object\n",
      "codigo_justificativa      object\n",
      "dtype: object\n",
      "\n",
      "-----[T] Transforming the data types-----\n",
      "\n",
      "icao_empresa_aerea        string[python]\n",
      "numero_voo                string[python]\n",
      "codigo_autorizacao        string[python]\n",
      "codigo_tipo_linha         string[python]\n",
      "icao_aerodromo_origem     string[python]\n",
      "icao_aerodromo_destino    string[python]\n",
      "partida_prevista          datetime64[ns]\n",
      "partida_real              datetime64[ns]\n",
      "chegada_prevista          datetime64[ns]\n",
      "chegada_real              datetime64[ns]\n",
      "situacao_voo              string[python]\n",
      "codigo_justificativa      string[python]\n",
      "dtype: object\n",
      "\n",
      "-----[L] Loading to the database-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "535803"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n-----[E] Extracting data of JSON files-----\\n\")\n",
    "\n",
    "# Declare the path to the folder containing the JSON files\n",
    "path = r'source\\VRA'\n",
    "\n",
    "# Declare the variable to store all JSON data\n",
    "data_json = pd.DataFrame()\n",
    "\n",
    "schema = {\n",
    "    'icao_empresa_aerea':TEXT,\n",
    "    'numero_voo':TEXT,\n",
    "    'codigo_autorizacao':TEXT,\n",
    "    'codigo_tipo_linha':TEXT,\n",
    "    'icao_aerodromo_origem':TEXT,\n",
    "    'icao_aerodromo_destino':TEXT,\n",
    "    'partida_prevista':DATETIME,\n",
    "    'partida_real':DATETIME,\n",
    "    'chegada_prevista':DATETIME,\n",
    "    'chegada_real':DATETIME,\n",
    "    'situacao_voo':TEXT,\n",
    "    'codigo_justificativa':TEXT}\n",
    "\n",
    "# Loop through each JSON file in the folder\n",
    "for file in os.listdir(path):\n",
    "    with open(os.path.join(path, file), 'r',encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "    print(f'Extracted {file} -> {len(data)} rows')\n",
    "    data_json = pd.concat([data_json, pd.DataFrame(data)], ignore_index=True)\n",
    "print(f\"\\nExtracted -> {len(data_json)} rows\")\n",
    "\n",
    "# Normalize the headers for snake case pattern\n",
    "rename_dict = {\n",
    "    \"ICAOEmpresaAérea\":\"icao_empresa_aerea\",\n",
    "    \"NúmeroVoo\":\"numero_voo\",\n",
    "    \"CódigoAutorização\":\"codigo_autorizacao\",\n",
    "    \"CódigoTipoLinha\":\"codigo_tipo_linha\",\n",
    "    \"ICAOAeródromoOrigem\":\"icao_aerodromo_origem\",\n",
    "    \"ICAOAeródromoDestino\":\"icao_aerodromo_destino\",\n",
    "    \"PartidaPrevista\":\"partida_prevista\",\n",
    "    \"PartidaReal\":\"partida_real\",\n",
    "    \"ChegadaPrevista\":\"chegada_prevista\",\n",
    "    \"ChegadaReal\":\"chegada_real\",\n",
    "    \"SituaçãoVoo\":\"situacao_voo\",\n",
    "    \"CódigoJustificativa\":\"codigo_justificativa\"}\n",
    "\n",
    "data_json.rename(columns=rename_dict,inplace=True)\n",
    "print(f'\\n{data_json.dtypes}\\n')\n",
    "\n",
    "# Transforming datetime data types\n",
    "print(\"-----[T] Transforming the data types-----\")\n",
    "data_json = trf_dtypes(schema,data_json)\n",
    "print(f'\\n{data_json.dtypes}\\n')\n",
    "\n",
    "# Replace NaN values\n",
    "# data_json = data_json.replace(pd.NA,None)\n",
    "# data_json = data_json.where(pd.notna(data_json), None)\n",
    "\n",
    "# Saving the data as a SQLite file\n",
    "print(\"-----[L] Loading to the database-----\")\n",
    "data_json.to_sql('vra', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace',dtype=schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solution for the Second question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----[E] Extracting data of CSV files-----\n",
      "\n",
      "Extracted ANAC_20211220_203627.csv -> 13 rows\n",
      "Extracted ANAC_20211220_203643.csv -> 5 rows\n",
      "Extracted ANAC_20211220_203733.csv -> 2 rows\n",
      "\n",
      "Extracted -> 20 rows\n",
      "\n",
      "razao_social                        object\n",
      "icao_iata                           object\n",
      "cnpj                                object\n",
      "atividades_aereas                   object\n",
      "endereco_sede                       object\n",
      "telefone                            object\n",
      "e_mail                              object\n",
      "decisao_operacional                 object\n",
      "data_decisao_operacional    datetime64[ns]\n",
      "validade_operacional        datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "-----[T] Transforming data -----\n",
      "\n",
      "razao_social                string[python]\n",
      "cnpj                        string[python]\n",
      "atividades_aereas           string[python]\n",
      "endereco_sede               string[python]\n",
      "telefone                    string[python]\n",
      "e_mail                      string[python]\n",
      "decisao_operacional         string[python]\n",
      "data_decisao_operacional    datetime64[ns]\n",
      "validade_operacional        datetime64[ns]\n",
      "icao                        string[python]\n",
      "iata                        string[python]\n",
      "dtype: object\n",
      "\n",
      "-----[L] Loading to the database-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:57: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_30128\\1056845284.py:57: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_csv.to_sql('air_cia', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace',dtype=schema)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n-----[E] Extracting data of CSV files-----\\n\")\n",
    "\n",
    "# Declare the path to the folder containing the JSON files\n",
    "path = r'source\\AIR_CIA'\n",
    "\n",
    "# Declare the variable to store all JSON data\n",
    "data_csv = pd.DataFrame()\n",
    "\n",
    "schema = {\n",
    "        'razao_social':TEXT,\n",
    "        'icao_iata':TEXT,\n",
    "        'cnpj':TEXT,\n",
    "        'atividades_aereas':TEXT,\n",
    "        'endereco_sede':TEXT,\n",
    "        'telefone':TEXT,\n",
    "        'e_mail':TEXT,\n",
    "        'decisao_operacional':TEXT,\n",
    "        'data_decisao_operacional':DATE,\n",
    "        'validade_operacional':DATE\n",
    "        }\n",
    "\n",
    "# Loop through each CSV file in the folder\n",
    "names = list(schema.keys())\n",
    "for file in os.listdir(path):\n",
    "    df = pd.read_csv(os.path.join(path, file), encoding='utf-8', sep=';', names=names,dtype=str,parse_dates=names[8:],dayfirst=True,header=0)\n",
    "    print(f'Extracted {file} -> {len(df)} rows')\n",
    "    data_csv = pd.concat([data_csv, df], ignore_index=True)\n",
    "print(f\"\\nExtracted -> {len(data_csv)} rows\")\n",
    "print(f'\\n{data_csv.dtypes}\\n')\n",
    "\n",
    "# Splitting the icao_iata column\n",
    "print(\"-----[T] Transforming data -----\")\n",
    "data_csv[['icao', 'iata']] = data_csv['icao_iata'].str.split(' ', expand=True)\n",
    "\n",
    "# Removing the icao_iata column\n",
    "data_csv = data_csv.drop('icao_iata', axis=1)\n",
    "del schema['icao_iata']\n",
    "\n",
    "# Adding new columns in the schema dictionary\n",
    "schema['icao'] = TEXT\n",
    "schema['iata'] = TEXT\n",
    "\n",
    "# Transforming data types\n",
    "data_csv = trf_dtypes(schema,data_csv)\n",
    "print(f'\\n{data_csv.dtypes}\\n')\n",
    "\n",
    "# data_csv.replace({pd.NaT: None}, inplace=True)\n",
    "# data_csv = data_csv.replace([float('nan')], [None])\n",
    "\n",
    "# print(data_csv['data_decisao_operacional'])\n",
    "# print(data_csv['validade_operacional'])\n",
    "\n",
    "# data_csv = data_csv.where(pd.notna(data_csv), None)\n",
    "\n",
    "# Saving the data as a SQLite file\n",
    "print(\"-----[L] Loading to the database-----\")\n",
    "data_csv.to_sql('air_cia', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace',dtype=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solution for the third question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint\n",
    "url = \"https://airport-info.p.rapidapi.com/airport\"\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"58b48914f9mshcdae739ac9f0de7p15b71djsnb39bd8f9e064\",\n",
    "\t\"X-RapidAPI-Host\": \"airport-info.p.rapidapi.com\"\n",
    "}\n",
    "# List for storing the data\n",
    "data = []\n",
    "\n",
    "# Get the all unique IICAOs\n",
    "icao_destino = data_json['icao_aerodromo_destino'].unique().tolist()\n",
    "icao_origem = data_json['icao_aerodromo_origem'].unique().tolist()\n",
    "# icao_air_cia = data_csv['icao'].unique().tolist()\n",
    "icao = icao_destino + icao_origem\n",
    "icao = list(set(icao))\n",
    "print(f'{len(icao)} ICAOs to search')\n",
    "\n",
    "# Loop through each ICAO\n",
    "for i in icao:\n",
    "    # print(f'Searching {i}')\n",
    "    # Define the querystring parameters\n",
    "    querystring = {\"icao\":i}\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        \n",
    "        try:\n",
    "            # Verify if the 'error' key is present in the response\n",
    "            erro = result['error']\n",
    "            print(f'{i} -> {erro}')\n",
    "        except:\n",
    "            # Add the data to the list\n",
    "            data.append(response.json())\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "print(f'\\nExtracted -> {len(data)} rows')\n",
    "\n",
    "# Save the data to a SQLite database\n",
    "df = pd.DataFrame(data)\n",
    "df = df.replace('', None)\n",
    "df.to_sql('airport', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solution for the fourth question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_27200\\2995110894.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  conn = sqlite3.connect('.\\data\\data.db')\n"
     ]
    }
   ],
   "source": [
    "# Conecte-se ao banco de dados SQLite (ou crie um novo)\n",
    "conn = sqlite3.connect('.\\data\\data.db')\n",
    "\n",
    "# Crie um cursor para executar comandos SQL\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Defina o comando SQL para criar uma view\n",
    "query = \"\"\"\n",
    "CREATE VIEW top_air_routes_per_company AS\n",
    "SELECT \n",
    "cia.razao_social AS razao_social, rotas.icao_empresa_aerea, rotas.frequencia, rank,\n",
    "rotas.icao_aerodromo_origem AS icao_origem, origem.name AS origem_name, origem.state AS origem_state, \n",
    "rotas.icao_aerodromo_destino AS icao_destino, destino.name AS destino_name,destino.state AS destino_state \n",
    "FROM (SELECT icao_empresa_aerea, icao_aerodromo_origem, icao_aerodromo_destino,frequencia, \n",
    "Rank() OVER (PARTITION BY icao_empresa_aerea ORDER BY frequencia DESC) AS rank \n",
    "FROM (SELECT icao_empresa_aerea, icao_aerodromo_origem, icao_aerodromo_destino, count(*) AS frequencia FROM vra GROUP BY 1,2,3)) rotas\n",
    "LEFT JOIN airport origem\n",
    "ON rotas.icao_aerodromo_origem = origem.icao\n",
    "LEFT JOIN airport destino\n",
    "ON rotas.icao_aerodromo_destino = destino.icao\n",
    "INNER JOIN air_cia cia\n",
    "ON rotas.icao_empresa_aerea = cia.icao\n",
    "WHERE rank =1\n",
    "GROUP BY razao_social,rotas.icao_empresa_aerea,origem_name,origem_state,destino_name,destino_state;\n",
    "\"\"\"\n",
    "\n",
    "# Execute o comando SQL para criar a view\n",
    "cursor.execute(query)\n",
    "\n",
    "# Certifique-se de confirmar as alterações e fechar a conexão\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conecte-se ao banco de dados SQLite (ou crie um novo)\n",
    "conn = sqlite3.connect('.\\data\\data.db')\n",
    "\n",
    "# Crie um cursor para executar comandos SQL\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Defina o comando SQL para criar uma view\n",
    "query = \"\"\"\n",
    "CREATE VIEW top_company_per_airport AS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute o comando SQL para criar a view\n",
    "cursor.execute(query)\n",
    "\n",
    "# Certifique-se de confirmar as alterações e fechar a conexão\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
