{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "from db import Session, Base, engine\n",
    "from schemas import vra\n",
    "\n",
    "def date_parser(data_str):\n",
    "    \"\"\"\n",
    "        Format any date in YYYY-MM-DD HH:MM:SS\n",
    "    Args:\n",
    "        data_str (str): string with the date\n",
    "\n",
    "    Returns:\n",
    "        str: string with the date formatted in YYYY-MM-DD HH:MM:SS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tenta analisar a data de entrada em diferentes formatos\n",
    "        data_str = str(data_str)\n",
    "        if data_str[:2] == '00':\n",
    "            data_str = '20'+str(data_str)[2:]\n",
    "        # data = datetime(year=int('20'+data_str[2:4]), month=int(data_str[5:7], 10), day=int(data_str[8:10]), hour=int(data_str[11:13]), minute=int(data_str[14:16]), second=int(data_str[17:19]),microsecond=int(0))\n",
    "        data = datetime.strptime(data_str, '%Y-%m-%d %H:%M:%S')\n",
    "        if data_str[:2] == '00':\n",
    "            print(data_str)\n",
    "            print(data)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            data = datetime.strptime(data_str, '%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                data = datetime.strptime(data_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    data = datetime.strptime(data_str, '%d/%m/%Y %H:%M:%S')\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        data = datetime.strptime(data_str, '%d/%m/%Y %H:%M')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            data = datetime.strptime(data_str, '%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                data = datetime.strptime(data_str, '%Y-%m-%d %H:%M')\n",
    "                            except ValueError:\n",
    "                                # print(\"Data inválida:\", data_str)\n",
    "                                return None  # Retornar None se a data não pôde ser analisada\n",
    "\n",
    "    # Formate a data no formato desejado\n",
    "    data_formatada = data.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    data_obj = datetime.strptime(data_formatada, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return data_obj\n",
    "\n",
    "def trf_dtypes(schema,dataframe):\n",
    "    \"\"\"\n",
    "    Transforma os tipos de dados do dataframe de acordo com o schema especificado.\n",
    "\n",
    "    Args:\n",
    "        schema_bq (dict): Dicionário contendo o schema do BigQuery, com os nomes das colunas e os tipos de dados.\n",
    "        dataframe (pandas.DataFrame): O dataframe a ser transformado.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário contendo as informações do schema e o dataframe transformado.\n",
    "    \"\"\"\n",
    "    # print(dataframe.dtypes)\n",
    "    for key, value in schema.items():\n",
    "        # print(f'Parsing {key} for type {value}')\n",
    "        # dataframe = dataframe.rep\n",
    "        match(value):\n",
    "            case 'Integer':\n",
    "                dataframe[key] = dataframe[key].astype(pd.Int64Dtype())\n",
    "            case 'DateTime':\n",
    "                dataframe[key] = dataframe[key].apply(date_parser)\n",
    "                # dataframe[key] = pd.to_datetime(dataframe[key],format='%Y-%m-%d %H:%M:%S')\n",
    "            # case 'Float':\n",
    "            #     dataframe[key] = dataframe[key].apply(trf_numeric)\n",
    "            #     dataframe[key] = dataframe[key].round(decimals=7).astype(float)\n",
    "            #     context = decimal.Context(prec=10,Emax=99999, Emin=-99999)\n",
    "            #     dataframe[key] = dataframe[key].apply(context.create_decimal_from_float)\n",
    "            case 'String':\n",
    "                # dataframe[key] = dataframe[key].apply(trf_str)\n",
    "                dataframe[key] = dataframe[key].replace(\"null\", None)\n",
    "                dataframe[key] = dataframe[key].astype(pd.StringDtype())\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creation of the SQLite Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criação do banco de dados\n",
    "# session = Session()\n",
    "# Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solution for the first question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:75: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:75: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_23436\\1384376854.py:75: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  data_json.to_sql('vra', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process of loading the JSON data\n",
      "Loaded VRA_20211.json -> 58550 rows\n",
      "Loaded VRA_202110.json -> 59430 rows\n",
      "Loaded VRA_202111.json -> 64004 rows\n",
      "Loaded VRA_20212.json -> 43692 rows\n",
      "Loaded VRA_20213.json -> 39514 rows\n",
      "Loaded VRA_20214.json -> 29122 rows\n",
      "Loaded VRA_20215.json -> 35750 rows\n",
      "Loaded VRA_20216.json -> 40955 rows\n",
      "Loaded VRA_20217.json -> 53313 rows\n",
      "Loaded VRA_20218.json -> 54928 rows\n",
      "Loaded VRA_20219.json -> 56545 rows\n",
      "Finished loading the JSON data -> 535803 rows\n",
      "icao_empresa_aerea        object\n",
      "numero_voo                object\n",
      "codigo_autorizacao        object\n",
      "codigo_tipo_linha         object\n",
      "icao_aerodromo_origem     object\n",
      "icao_aerodromo_destino    object\n",
      "partida_prevista          object\n",
      "partida_real              object\n",
      "chegada_prevista          object\n",
      "chegada_real              object\n",
      "situacao_voo              object\n",
      "codigo_justificativa      object\n",
      "dtype: object\n",
      "Parsing icao_empresa_aerea for type String\n",
      "Parsing numero_voo for type String\n",
      "Parsing codigo_autorizacao for type String\n",
      "Parsing codigo_tipo_linha for type String\n",
      "Parsing icao_aerodromo_origem for type String\n",
      "Parsing icao_aerodromo_destino for type String\n",
      "Parsing partida_prevista for type DateTime\n",
      "Parsing partida_real for type DateTime\n",
      "0021-10-20 08:10:00\n",
      "0021-10-20 08:10:00\n",
      "Parsing chegada_prevista for type DateTime\n",
      "Parsing chegada_real for type DateTime\n",
      "Parsing situacao_voo for type String\n",
      "Parsing codigo_justificativa for type String\n",
      "icao_empresa_aerea        string[python]\n",
      "numero_voo                string[python]\n",
      "codigo_autorizacao        string[python]\n",
      "codigo_tipo_linha         string[python]\n",
      "icao_aerodromo_origem     string[python]\n",
      "icao_aerodromo_destino    string[python]\n",
      "partida_prevista          datetime64[ns]\n",
      "partida_real                      object\n",
      "chegada_prevista          datetime64[ns]\n",
      "chegada_real              datetime64[ns]\n",
      "situacao_voo              string[python]\n",
      "codigo_justificativa      string[python]\n",
      "dtype: object\n",
      "Saving to the database\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "535803"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting the process of loading the JSON data\")\n",
    "\n",
    "# Declare the path to the folder containing the JSON files\n",
    "path = r'source\\VRA'\n",
    "\n",
    "# Declare the variable to store all JSON data\n",
    "data_json = pd.DataFrame()\n",
    "\n",
    "# Loop through each JSON file in the folder\n",
    "for file in os.listdir(path):\n",
    "    with open(os.path.join(path, file), 'r',encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "    print(f'Loaded {file} -> {len(data)} rows')\n",
    "    data_json = pd.concat([data_json, pd.DataFrame(data)], ignore_index=True)\n",
    "print(f\"Finished loading the JSON data -> {len(data_json)} rows\")\n",
    "\n",
    "# Normalize the headers for snake case pattern\n",
    "rename_dict = {\n",
    "    \"ICAOEmpresaAérea\":\"icao_empresa_aerea\",\n",
    "    \"NúmeroVoo\":\"numero_voo\",\n",
    "    \"CódigoAutorização\":\"codigo_autorizacao\",\n",
    "    \"CódigoTipoLinha\":\"codigo_tipo_linha\",\n",
    "    \"ICAOAeródromoOrigem\":\"icao_aerodromo_origem\",\n",
    "    \"ICAOAeródromoDestino\":\"icao_aerodromo_destino\",\n",
    "    \"PartidaPrevista\":\"partida_prevista\",\n",
    "    \"PartidaReal\":\"partida_real\",\n",
    "    \"ChegadaPrevista\":\"chegada_prevista\",\n",
    "    \"ChegadaReal\":\"chegada_real\",\n",
    "    \"SituaçãoVoo\":\"situacao_voo\",\n",
    "    \"CódigoJustificativa\":\"codigo_justificativa\"}\n",
    "\n",
    "data_json.rename(columns=rename_dict,inplace=True)\n",
    "# print(data_json)\n",
    "\n",
    "schema = {\n",
    "    # 'id':'Integer',\n",
    "    'icao_empresa_aerea':'String',\n",
    "    'numero_voo':'String',\n",
    "    'codigo_autorizacao':'String',\n",
    "    'codigo_tipo_linha':'String',\n",
    "    'icao_aerodromo_origem':'String',\n",
    "    'icao_aerodromo_destino':'String',\n",
    "    'partida_prevista':'DateTime',\n",
    "    'partida_real':'DateTime',\n",
    "    'chegada_prevista':'DateTime',\n",
    "    'chegada_real':'DateTime',\n",
    "    'situacao_voo':'String',\n",
    "    'codigo_justificativa':'String'\n",
    "}\n",
    "\n",
    "# Transforming datetime data types\n",
    "# data_json = trf_data(['partida_prevista','partida_real','chegada_prevista','chegada_real'],data_json)\n",
    "print(\"Transforming the data types\")\n",
    "print('Before:\\n',data_json.dtypes)\n",
    "data_json = trf_dtypes(schema,data_json)\n",
    "print('After:\\n',data_json.dtypes)\n",
    "# data_json = data_json.fillna(None)\n",
    "data_json = data_json.replace(pd.NA,None)\n",
    "data_json = data_json.where(pd.notna(data_json), None)\n",
    "print(\"Saving to the database\")\n",
    "# dado = vra(**data_json) \n",
    "# dado = vra(**data_json.to_dict(orient='records')) \n",
    "# session.add(dado)\n",
    "\n",
    "# Itere pelas linhas do DataFrame\n",
    "# for index, row in data_json.iterrows():\n",
    "#     # Crie uma instância da classe vra com base nos valores da linha\n",
    "    \n",
    "#     dado = vra(**row.to_dict())\n",
    "\n",
    "#     # Adicione a instância à sessão\n",
    "#     session.add(dado)\n",
    "\n",
    "# session.commit()\n",
    "# Saving the data as a SQLite file\n",
    "# data_json.to_sql('vra', con='sqlite:///vra.db', index=False,if_exists='replace')\n",
    "data_json.to_sql('vra', con='sqlite:///data\\data.db?check_same_thread=False', index=False,if_exists='replace')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine, Column, Integer, DateTime\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "# from sqlalchemy.orm import sessionmaker\n",
    "# from datetime import datetime\n",
    "# from sqlalchemy import inspect\n",
    "\n",
    "# # Defina a classe do modelo com uma coluna de data e hora\n",
    "# Base = declarative_base()\n",
    "\n",
    "# class Exemplo(Base):\n",
    "#     __tablename__ = 'exemplo'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     data_hora = Column(DateTime)\n",
    "\n",
    "# # Crie uma conexão com o banco de dados SQLite\n",
    "# engine = create_engine('sqlite:///exemplo.db')\n",
    "\n",
    "# # Crie as tabelas no banco de dados\n",
    "# Base.metadata.create_all(engine)\n",
    "\n",
    "# # Crie uma instância da classe do modelo e atribua None à coluna de data e hora\n",
    "# exemplo = Exemplo(data_hora=None)\n",
    "\n",
    "# # Inicie uma sessão do SQLAlchemy\n",
    "# Session = sessionmaker(bind=engine)\n",
    "# session = Session()\n",
    "\n",
    "# # Adicione o objeto à sessão e cometa a transação\n",
    "# session.add(exemplo)\n",
    "# session.commit()\n",
    "\n",
    "# # Verifique o resultado\n",
    "# inspector = inspect(engine)\n",
    "# columns = inspector.get_columns('exemplo')\n",
    "# for column in columns:\n",
    "#     print(f\"{column['name']}: {getattr(exemplo, column['name'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
